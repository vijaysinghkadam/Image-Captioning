{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vijay/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pycocotools.coco import COCO\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pickle\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.index = 0\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.index\n",
    "            self.idx2word[self.index] = word\n",
    "            self.index += 1\n",
    "            \n",
    "    def __call__(self,word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(json,threshold):\n",
    "    coco = COCO(json)\n",
    "    counter = Counter()\n",
    "    ids = coco.anns.keys()\n",
    "    \n",
    "    for i,no in enumerate(ids):\n",
    "        caption = str(coco.anns[no]['caption'])\n",
    "        tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
    "        counter.update(tokens)\n",
    "        \n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(\"[{}/{}] Tokenized the captions \".format(i+1,len(ids)))\n",
    "    \n",
    "    words = [word for word,cnt in counter.items() if cnt>=threshold]\n",
    "    \n",
    "    vocab = Vocabulary()\n",
    "    vocab.add_word('<pad>')\n",
    "    vocab.add_word('<start>')\n",
    "    vocab.add_word('<end>')\n",
    "    vocab.add_word('<unk>')\n",
    "                  \n",
    "    for i,word in enumerate(words):\n",
    "        vocab.add_word(word)\n",
    "        \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    vocab = build_vocab(json = args.json_path , threshold = args.threshold)\n",
    "    vocab_path = args.vocab_path\n",
    "    with open(vocab_path,'wb') as f:\n",
    "        pickle.dump(vocab , f)\n",
    "    \n",
    "    print('total vocabulary size is {}'.format(len(vocab)))\n",
    "    print('saved the vocabulary to {}'.format(vocab_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.49s)\n",
      "creating index...\n",
      "index created!\n",
      "[1000/414113] Tokenized the captions \n",
      "[2000/414113] Tokenized the captions \n",
      "[3000/414113] Tokenized the captions \n",
      "[4000/414113] Tokenized the captions \n",
      "[5000/414113] Tokenized the captions \n",
      "[6000/414113] Tokenized the captions \n",
      "[7000/414113] Tokenized the captions \n",
      "[8000/414113] Tokenized the captions \n",
      "[9000/414113] Tokenized the captions \n",
      "[10000/414113] Tokenized the captions \n",
      "[11000/414113] Tokenized the captions \n",
      "[12000/414113] Tokenized the captions \n",
      "[13000/414113] Tokenized the captions \n",
      "[14000/414113] Tokenized the captions \n",
      "[15000/414113] Tokenized the captions \n",
      "[16000/414113] Tokenized the captions \n",
      "[17000/414113] Tokenized the captions \n",
      "[18000/414113] Tokenized the captions \n",
      "[19000/414113] Tokenized the captions \n",
      "[20000/414113] Tokenized the captions \n",
      "[21000/414113] Tokenized the captions \n",
      "[22000/414113] Tokenized the captions \n",
      "[23000/414113] Tokenized the captions \n",
      "[24000/414113] Tokenized the captions \n",
      "[25000/414113] Tokenized the captions \n",
      "[26000/414113] Tokenized the captions \n",
      "[27000/414113] Tokenized the captions \n",
      "[28000/414113] Tokenized the captions \n",
      "[29000/414113] Tokenized the captions \n",
      "[30000/414113] Tokenized the captions \n",
      "[31000/414113] Tokenized the captions \n",
      "[32000/414113] Tokenized the captions \n",
      "[33000/414113] Tokenized the captions \n",
      "[34000/414113] Tokenized the captions \n",
      "[35000/414113] Tokenized the captions \n",
      "[36000/414113] Tokenized the captions \n",
      "[37000/414113] Tokenized the captions \n",
      "[38000/414113] Tokenized the captions \n",
      "[39000/414113] Tokenized the captions \n",
      "[40000/414113] Tokenized the captions \n",
      "[41000/414113] Tokenized the captions \n",
      "[42000/414113] Tokenized the captions \n",
      "[43000/414113] Tokenized the captions \n",
      "[44000/414113] Tokenized the captions \n",
      "[45000/414113] Tokenized the captions \n",
      "[46000/414113] Tokenized the captions \n",
      "[47000/414113] Tokenized the captions \n",
      "[48000/414113] Tokenized the captions \n",
      "[49000/414113] Tokenized the captions \n",
      "[50000/414113] Tokenized the captions \n",
      "[51000/414113] Tokenized the captions \n",
      "[52000/414113] Tokenized the captions \n",
      "[53000/414113] Tokenized the captions \n",
      "[54000/414113] Tokenized the captions \n",
      "[55000/414113] Tokenized the captions \n",
      "[56000/414113] Tokenized the captions \n",
      "[57000/414113] Tokenized the captions \n",
      "[58000/414113] Tokenized the captions \n",
      "[59000/414113] Tokenized the captions \n",
      "[60000/414113] Tokenized the captions \n",
      "[61000/414113] Tokenized the captions \n",
      "[62000/414113] Tokenized the captions \n",
      "[63000/414113] Tokenized the captions \n",
      "[64000/414113] Tokenized the captions \n",
      "[65000/414113] Tokenized the captions \n",
      "[66000/414113] Tokenized the captions \n",
      "[67000/414113] Tokenized the captions \n",
      "[68000/414113] Tokenized the captions \n",
      "[69000/414113] Tokenized the captions \n",
      "[70000/414113] Tokenized the captions \n",
      "[71000/414113] Tokenized the captions \n",
      "[72000/414113] Tokenized the captions \n",
      "[73000/414113] Tokenized the captions \n",
      "[74000/414113] Tokenized the captions \n",
      "[75000/414113] Tokenized the captions \n",
      "[76000/414113] Tokenized the captions \n",
      "[77000/414113] Tokenized the captions \n",
      "[78000/414113] Tokenized the captions \n",
      "[79000/414113] Tokenized the captions \n",
      "[80000/414113] Tokenized the captions \n",
      "[81000/414113] Tokenized the captions \n",
      "[82000/414113] Tokenized the captions \n",
      "[83000/414113] Tokenized the captions \n",
      "[84000/414113] Tokenized the captions \n",
      "[85000/414113] Tokenized the captions \n",
      "[86000/414113] Tokenized the captions \n",
      "[87000/414113] Tokenized the captions \n",
      "[88000/414113] Tokenized the captions \n",
      "[89000/414113] Tokenized the captions \n",
      "[90000/414113] Tokenized the captions \n",
      "[91000/414113] Tokenized the captions \n",
      "[92000/414113] Tokenized the captions \n",
      "[93000/414113] Tokenized the captions \n",
      "[94000/414113] Tokenized the captions \n",
      "[95000/414113] Tokenized the captions \n",
      "[96000/414113] Tokenized the captions \n",
      "[97000/414113] Tokenized the captions \n",
      "[98000/414113] Tokenized the captions \n",
      "[99000/414113] Tokenized the captions \n",
      "[100000/414113] Tokenized the captions \n",
      "[101000/414113] Tokenized the captions \n",
      "[102000/414113] Tokenized the captions \n",
      "[103000/414113] Tokenized the captions \n",
      "[104000/414113] Tokenized the captions \n",
      "[105000/414113] Tokenized the captions \n",
      "[106000/414113] Tokenized the captions \n",
      "[107000/414113] Tokenized the captions \n",
      "[108000/414113] Tokenized the captions \n",
      "[109000/414113] Tokenized the captions \n",
      "[110000/414113] Tokenized the captions \n",
      "[111000/414113] Tokenized the captions \n",
      "[112000/414113] Tokenized the captions \n",
      "[113000/414113] Tokenized the captions \n",
      "[114000/414113] Tokenized the captions \n",
      "[115000/414113] Tokenized the captions \n",
      "[116000/414113] Tokenized the captions \n",
      "[117000/414113] Tokenized the captions \n",
      "[118000/414113] Tokenized the captions \n",
      "[119000/414113] Tokenized the captions \n",
      "[120000/414113] Tokenized the captions \n",
      "[121000/414113] Tokenized the captions \n",
      "[122000/414113] Tokenized the captions \n",
      "[123000/414113] Tokenized the captions \n",
      "[124000/414113] Tokenized the captions \n",
      "[125000/414113] Tokenized the captions \n",
      "[126000/414113] Tokenized the captions \n",
      "[127000/414113] Tokenized the captions \n",
      "[128000/414113] Tokenized the captions \n",
      "[129000/414113] Tokenized the captions \n",
      "[130000/414113] Tokenized the captions \n",
      "[131000/414113] Tokenized the captions \n",
      "[132000/414113] Tokenized the captions \n",
      "[133000/414113] Tokenized the captions \n",
      "[134000/414113] Tokenized the captions \n",
      "[135000/414113] Tokenized the captions \n",
      "[136000/414113] Tokenized the captions \n",
      "[137000/414113] Tokenized the captions \n",
      "[138000/414113] Tokenized the captions \n",
      "[139000/414113] Tokenized the captions \n",
      "[140000/414113] Tokenized the captions \n",
      "[141000/414113] Tokenized the captions \n",
      "[142000/414113] Tokenized the captions \n",
      "[143000/414113] Tokenized the captions \n",
      "[144000/414113] Tokenized the captions \n",
      "[145000/414113] Tokenized the captions \n",
      "[146000/414113] Tokenized the captions \n",
      "[147000/414113] Tokenized the captions \n",
      "[148000/414113] Tokenized the captions \n",
      "[149000/414113] Tokenized the captions \n",
      "[150000/414113] Tokenized the captions \n",
      "[151000/414113] Tokenized the captions \n",
      "[152000/414113] Tokenized the captions \n",
      "[153000/414113] Tokenized the captions \n",
      "[154000/414113] Tokenized the captions \n",
      "[155000/414113] Tokenized the captions \n",
      "[156000/414113] Tokenized the captions \n",
      "[157000/414113] Tokenized the captions \n",
      "[158000/414113] Tokenized the captions \n",
      "[159000/414113] Tokenized the captions \n",
      "[160000/414113] Tokenized the captions \n",
      "[161000/414113] Tokenized the captions \n",
      "[162000/414113] Tokenized the captions \n",
      "[163000/414113] Tokenized the captions \n",
      "[164000/414113] Tokenized the captions \n",
      "[165000/414113] Tokenized the captions \n",
      "[166000/414113] Tokenized the captions \n",
      "[167000/414113] Tokenized the captions \n",
      "[168000/414113] Tokenized the captions \n",
      "[169000/414113] Tokenized the captions \n",
      "[170000/414113] Tokenized the captions \n",
      "[171000/414113] Tokenized the captions \n",
      "[172000/414113] Tokenized the captions \n",
      "[173000/414113] Tokenized the captions \n",
      "[174000/414113] Tokenized the captions \n",
      "[175000/414113] Tokenized the captions \n",
      "[176000/414113] Tokenized the captions \n",
      "[177000/414113] Tokenized the captions \n",
      "[178000/414113] Tokenized the captions \n",
      "[179000/414113] Tokenized the captions \n",
      "[180000/414113] Tokenized the captions \n",
      "[181000/414113] Tokenized the captions \n",
      "[182000/414113] Tokenized the captions \n",
      "[183000/414113] Tokenized the captions \n",
      "[184000/414113] Tokenized the captions \n",
      "[185000/414113] Tokenized the captions \n",
      "[186000/414113] Tokenized the captions \n",
      "[187000/414113] Tokenized the captions \n",
      "[188000/414113] Tokenized the captions \n",
      "[189000/414113] Tokenized the captions \n",
      "[190000/414113] Tokenized the captions \n",
      "[191000/414113] Tokenized the captions \n",
      "[192000/414113] Tokenized the captions \n",
      "[193000/414113] Tokenized the captions \n",
      "[194000/414113] Tokenized the captions \n",
      "[195000/414113] Tokenized the captions \n",
      "[196000/414113] Tokenized the captions \n",
      "[197000/414113] Tokenized the captions \n",
      "[198000/414113] Tokenized the captions \n",
      "[199000/414113] Tokenized the captions \n",
      "[200000/414113] Tokenized the captions \n",
      "[201000/414113] Tokenized the captions \n",
      "[202000/414113] Tokenized the captions \n",
      "[203000/414113] Tokenized the captions \n",
      "[204000/414113] Tokenized the captions \n",
      "[205000/414113] Tokenized the captions \n",
      "[206000/414113] Tokenized the captions \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207000/414113] Tokenized the captions \n",
      "[208000/414113] Tokenized the captions \n",
      "[209000/414113] Tokenized the captions \n",
      "[210000/414113] Tokenized the captions \n",
      "[211000/414113] Tokenized the captions \n",
      "[212000/414113] Tokenized the captions \n",
      "[213000/414113] Tokenized the captions \n",
      "[214000/414113] Tokenized the captions \n",
      "[215000/414113] Tokenized the captions \n",
      "[216000/414113] Tokenized the captions \n",
      "[217000/414113] Tokenized the captions \n",
      "[218000/414113] Tokenized the captions \n",
      "[219000/414113] Tokenized the captions \n",
      "[220000/414113] Tokenized the captions \n",
      "[221000/414113] Tokenized the captions \n",
      "[222000/414113] Tokenized the captions \n",
      "[223000/414113] Tokenized the captions \n",
      "[224000/414113] Tokenized the captions \n",
      "[225000/414113] Tokenized the captions \n",
      "[226000/414113] Tokenized the captions \n",
      "[227000/414113] Tokenized the captions \n",
      "[228000/414113] Tokenized the captions \n",
      "[229000/414113] Tokenized the captions \n",
      "[230000/414113] Tokenized the captions \n",
      "[231000/414113] Tokenized the captions \n",
      "[232000/414113] Tokenized the captions \n",
      "[233000/414113] Tokenized the captions \n",
      "[234000/414113] Tokenized the captions \n",
      "[235000/414113] Tokenized the captions \n",
      "[236000/414113] Tokenized the captions \n",
      "[237000/414113] Tokenized the captions \n",
      "[238000/414113] Tokenized the captions \n",
      "[239000/414113] Tokenized the captions \n",
      "[240000/414113] Tokenized the captions \n",
      "[241000/414113] Tokenized the captions \n",
      "[242000/414113] Tokenized the captions \n",
      "[243000/414113] Tokenized the captions \n",
      "[244000/414113] Tokenized the captions \n",
      "[245000/414113] Tokenized the captions \n",
      "[246000/414113] Tokenized the captions \n",
      "[247000/414113] Tokenized the captions \n",
      "[248000/414113] Tokenized the captions \n",
      "[249000/414113] Tokenized the captions \n",
      "[250000/414113] Tokenized the captions \n",
      "[251000/414113] Tokenized the captions \n",
      "[252000/414113] Tokenized the captions \n",
      "[253000/414113] Tokenized the captions \n",
      "[254000/414113] Tokenized the captions \n",
      "[255000/414113] Tokenized the captions \n",
      "[256000/414113] Tokenized the captions \n",
      "[257000/414113] Tokenized the captions \n",
      "[258000/414113] Tokenized the captions \n",
      "[259000/414113] Tokenized the captions \n",
      "[260000/414113] Tokenized the captions \n",
      "[261000/414113] Tokenized the captions \n",
      "[262000/414113] Tokenized the captions \n",
      "[263000/414113] Tokenized the captions \n",
      "[264000/414113] Tokenized the captions \n",
      "[265000/414113] Tokenized the captions \n",
      "[266000/414113] Tokenized the captions \n",
      "[267000/414113] Tokenized the captions \n",
      "[268000/414113] Tokenized the captions \n",
      "[269000/414113] Tokenized the captions \n",
      "[270000/414113] Tokenized the captions \n",
      "[271000/414113] Tokenized the captions \n",
      "[272000/414113] Tokenized the captions \n",
      "[273000/414113] Tokenized the captions \n",
      "[274000/414113] Tokenized the captions \n",
      "[275000/414113] Tokenized the captions \n",
      "[276000/414113] Tokenized the captions \n",
      "[277000/414113] Tokenized the captions \n",
      "[278000/414113] Tokenized the captions \n",
      "[279000/414113] Tokenized the captions \n",
      "[280000/414113] Tokenized the captions \n",
      "[281000/414113] Tokenized the captions \n",
      "[282000/414113] Tokenized the captions \n",
      "[283000/414113] Tokenized the captions \n",
      "[284000/414113] Tokenized the captions \n",
      "[285000/414113] Tokenized the captions \n",
      "[286000/414113] Tokenized the captions \n",
      "[287000/414113] Tokenized the captions \n",
      "[288000/414113] Tokenized the captions \n",
      "[289000/414113] Tokenized the captions \n",
      "[290000/414113] Tokenized the captions \n",
      "[291000/414113] Tokenized the captions \n",
      "[292000/414113] Tokenized the captions \n",
      "[293000/414113] Tokenized the captions \n",
      "[294000/414113] Tokenized the captions \n",
      "[295000/414113] Tokenized the captions \n",
      "[296000/414113] Tokenized the captions \n",
      "[297000/414113] Tokenized the captions \n",
      "[298000/414113] Tokenized the captions \n",
      "[299000/414113] Tokenized the captions \n",
      "[300000/414113] Tokenized the captions \n",
      "[301000/414113] Tokenized the captions \n",
      "[302000/414113] Tokenized the captions \n",
      "[303000/414113] Tokenized the captions \n",
      "[304000/414113] Tokenized the captions \n",
      "[305000/414113] Tokenized the captions \n",
      "[306000/414113] Tokenized the captions \n",
      "[307000/414113] Tokenized the captions \n",
      "[308000/414113] Tokenized the captions \n",
      "[309000/414113] Tokenized the captions \n",
      "[310000/414113] Tokenized the captions \n",
      "[311000/414113] Tokenized the captions \n",
      "[312000/414113] Tokenized the captions \n",
      "[313000/414113] Tokenized the captions \n",
      "[314000/414113] Tokenized the captions \n",
      "[315000/414113] Tokenized the captions \n",
      "[316000/414113] Tokenized the captions \n",
      "[317000/414113] Tokenized the captions \n",
      "[318000/414113] Tokenized the captions \n",
      "[319000/414113] Tokenized the captions \n",
      "[320000/414113] Tokenized the captions \n",
      "[321000/414113] Tokenized the captions \n",
      "[322000/414113] Tokenized the captions \n",
      "[323000/414113] Tokenized the captions \n",
      "[324000/414113] Tokenized the captions \n",
      "[325000/414113] Tokenized the captions \n",
      "[326000/414113] Tokenized the captions \n",
      "[327000/414113] Tokenized the captions \n",
      "[328000/414113] Tokenized the captions \n",
      "[329000/414113] Tokenized the captions \n",
      "[330000/414113] Tokenized the captions \n",
      "[331000/414113] Tokenized the captions \n",
      "[332000/414113] Tokenized the captions \n",
      "[333000/414113] Tokenized the captions \n",
      "[334000/414113] Tokenized the captions \n",
      "[335000/414113] Tokenized the captions \n",
      "[336000/414113] Tokenized the captions \n",
      "[337000/414113] Tokenized the captions \n",
      "[338000/414113] Tokenized the captions \n",
      "[339000/414113] Tokenized the captions \n",
      "[340000/414113] Tokenized the captions \n",
      "[341000/414113] Tokenized the captions \n",
      "[342000/414113] Tokenized the captions \n",
      "[343000/414113] Tokenized the captions \n",
      "[344000/414113] Tokenized the captions \n",
      "[345000/414113] Tokenized the captions \n",
      "[346000/414113] Tokenized the captions \n",
      "[347000/414113] Tokenized the captions \n",
      "[348000/414113] Tokenized the captions \n",
      "[349000/414113] Tokenized the captions \n",
      "[350000/414113] Tokenized the captions \n",
      "[351000/414113] Tokenized the captions \n",
      "[352000/414113] Tokenized the captions \n",
      "[353000/414113] Tokenized the captions \n",
      "[354000/414113] Tokenized the captions \n",
      "[355000/414113] Tokenized the captions \n",
      "[356000/414113] Tokenized the captions \n",
      "[357000/414113] Tokenized the captions \n",
      "[358000/414113] Tokenized the captions \n",
      "[359000/414113] Tokenized the captions \n",
      "[360000/414113] Tokenized the captions \n",
      "[361000/414113] Tokenized the captions \n",
      "[362000/414113] Tokenized the captions \n",
      "[363000/414113] Tokenized the captions \n",
      "[364000/414113] Tokenized the captions \n",
      "[365000/414113] Tokenized the captions \n",
      "[366000/414113] Tokenized the captions \n",
      "[367000/414113] Tokenized the captions \n",
      "[368000/414113] Tokenized the captions \n",
      "[369000/414113] Tokenized the captions \n",
      "[370000/414113] Tokenized the captions \n",
      "[371000/414113] Tokenized the captions \n",
      "[372000/414113] Tokenized the captions \n",
      "[373000/414113] Tokenized the captions \n",
      "[374000/414113] Tokenized the captions \n",
      "[375000/414113] Tokenized the captions \n",
      "[376000/414113] Tokenized the captions \n",
      "[377000/414113] Tokenized the captions \n",
      "[378000/414113] Tokenized the captions \n",
      "[379000/414113] Tokenized the captions \n",
      "[380000/414113] Tokenized the captions \n",
      "[381000/414113] Tokenized the captions \n",
      "[382000/414113] Tokenized the captions \n",
      "[383000/414113] Tokenized the captions \n",
      "[384000/414113] Tokenized the captions \n",
      "[385000/414113] Tokenized the captions \n",
      "[386000/414113] Tokenized the captions \n",
      "[387000/414113] Tokenized the captions \n",
      "[388000/414113] Tokenized the captions \n",
      "[389000/414113] Tokenized the captions \n",
      "[390000/414113] Tokenized the captions \n",
      "[391000/414113] Tokenized the captions \n",
      "[392000/414113] Tokenized the captions \n",
      "[393000/414113] Tokenized the captions \n",
      "[394000/414113] Tokenized the captions \n",
      "[395000/414113] Tokenized the captions \n",
      "[396000/414113] Tokenized the captions \n",
      "[397000/414113] Tokenized the captions \n",
      "[398000/414113] Tokenized the captions \n",
      "[399000/414113] Tokenized the captions \n",
      "[400000/414113] Tokenized the captions \n",
      "[401000/414113] Tokenized the captions \n",
      "[402000/414113] Tokenized the captions \n",
      "[403000/414113] Tokenized the captions \n",
      "[404000/414113] Tokenized the captions \n",
      "[405000/414113] Tokenized the captions \n",
      "[406000/414113] Tokenized the captions \n",
      "[407000/414113] Tokenized the captions \n",
      "[408000/414113] Tokenized the captions \n",
      "[409000/414113] Tokenized the captions \n",
      "[410000/414113] Tokenized the captions \n",
      "[411000/414113] Tokenized the captions \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[412000/414113] Tokenized the captions \n",
      "[413000/414113] Tokenized the captions \n",
      "[414000/414113] Tokenized the captions \n",
      "total vocabulary size is 9956\n",
      "saved the vocabulary to data/vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--json_path',type=str,\n",
    "                       default='data/annotations/captions_train2014.json',\n",
    "                       help = 'path for train in annotation file')\n",
    "    parser.add_argument('--vocab_path',type = str,\n",
    "                       default = 'data/vocab.pkl',\n",
    "                       help = 'path for vocabulary wrapper')\n",
    "    parser.add_argument('--threshold',type = int ,\n",
    "                       default = 4,\n",
    "                       help ='minimum word count threshold')\n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
