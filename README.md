# Image-Captioning


The goal of image captioning is to convert a given input image into a natural language description. The encoder-decoder framework is widely used for this task. The image encoder is a convolutional neural network (CNN). In this tutorial, we used resnet-152 model pretrained on the ILSVRC-2012-CLS image classification dataset. The decoder is a long short-term memory (LSTM) network.

![model.png](https://github.com/vijaysinghkadam/Image-Captioning/blob/master/images/model.png)
---

## Correct predictions after training:

![screenshot](https://github.com/vijaysinghkadam/Image-Captioning/blob/master/images/succ1.png)

![screenshot](https://github.com/vijaysinghkadam/Image-Captioning/blob/master/images/succ2.png)

![screenshot](https://github.com/vijaysinghkadam/Image-Captioning/blob/master/images/succ3.png)



## Some wrong predictions:

![screenshot](https://github.com/vijaysinghkadam/Image-Captioning/blob/master/images/fail1.png)

![screenshot](https://github.com/vijaysinghkadam/Image-Captioning/blob/master/images/fail2.png)

![screenshot](https://github.com/vijaysinghkadam/Image-Captioning/blob/master/images/fail3.png)


