{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(Dataset):\n",
    "    def __init__(self, root, json, vocab, transform = None):\n",
    "        \n",
    "        self.root = root\n",
    "        self.coco = COCO(json)\n",
    "        self.ids  = list(self.coco.anns.keys())\n",
    "        self.vocab = vocab\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        ann_id = self.ids[index]\n",
    "        caption = self.coco.anns[ann_id]['caption']\n",
    "        image_id = self.coco.anns[ann_id]['image_id']\n",
    "        image_name = self.coco.loadImgs(image_id)[0]['file_name']\n",
    "        \n",
    "        image = Image.open(os.path.join(self.root,image_name)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "             \n",
    "        tokens = nltk.tokenize.word_tokenize(str(caption).lower())\n",
    "        caption = []\n",
    "        caption.append(self.vocab('<start>'))\n",
    "        caption.extend([self.vocab(token) for token in tokens])\n",
    "        caption.append(self.vocab('<end>'))\n",
    "        target = torch.Tensor(caption)\n",
    "        \n",
    "        return image,target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(data):\n",
    "    \n",
    "    data.sort(key= lambda x: len(x[1]), reverse = True)\n",
    "    images , captions = zip(*data)\n",
    "    \n",
    "    images = torch.stack(images,0)\n",
    "    \n",
    "    lengths = [len(cap) for cap in captions]\n",
    "    targets = torch.zeros(len(captions),max(lengths)).long()\n",
    "    for i,cap in enumerate(captions):\n",
    "        end = lengths[i]\n",
    "        targets[i,:end] = cap[:end]\n",
    "    return images,targets,lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(root, json ,vocab , transform, batch_size ,shuffle ,num_workers):\n",
    "    coco = CocoDataset(root = root,\n",
    "                      json = json,\n",
    "                      vocab = vocab,\n",
    "                      transform = transform)\n",
    "    \n",
    "    data_loader = DataLoader(dataset= CocoDataset ,\n",
    "                            batch_size = batch_size,\n",
    "                            shuffle = shuffle,\n",
    "                            num_workers = num_workers,\n",
    "                            collate_fn = my_collate)\n",
    "    \n",
    "    return data_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
